# Описание проекта

## Исходные данные 

* **base.csv** - анонимизированный набор товаров. Каждый товар представлен как уникальный id(0-base, 1-base... n-base) и векторы признаков размерностью 72.


* **target.csv** - обучающий датасет. Каждая строчка - один товар, для которого известен уникальный id(0-query, 1-query... n-query), вектор признаков и id товаров из *base.csv*, который максимально похож на него(по мнению экспертов).


* **validation.csv** - датасет с товарами(уникальный id и вектор признаков), для которых надо найти наиболее близкие товары из *base.csv*


* **validation_answer.csv** - правильные ответы к предыдущемк файлу.

## Задача

* Разработать алгоритм который для всех товаров из Validation.csv предложит несколько вариантов наиболее похожих товаров из base 

* Оценить качество алгоритма по метрике accuracy@5

**Дополнительная задача**

* Реализовать REST API сервис, который по предложенным данным будем предлагать несколько похожих товаров.

## Реализация задачи:

### Aнализ данных

Некоторые признаки в исходном наборе данных имеют отличное от нормального распределение и больший разброс значений, относительно доминирующего большинства.

Особенностью алгоритмов KNN явлется восприимчивость к разнице ростояний между признаками. Так - большие растояния в алгоритме KNN оказывают принципиально большее влияние, чем небольшие. 
* Из этого мы будем проводить дальнейшую обработку.

### Обработка данных

Полная анонимность предоставляемых признаков помогает нашим дальнейшим решениям относиться к каждому столбцу и его обработке без пристрастия.

* Для усредннения баланса между признаками и уменьшения влияния индивидуальностей были протестированны: нормализация и стандартизация.

* Практическое тестирование показало отрицательное влияние признаков с очень большим стандартным отклонением, даже после стандартизации. Их удаление - прекрасное решение для улучшения точности моделей. 

Первичный тест проходил на модели faiss, где точность кластеризованного подбора ближайших векторов сначала составляла

* ~8%

после стандартизации:

* ~50%

после удаления "опасных" для KNN признаков:

* ~63%

### Использование моделей для построения рекомендательной системы  

Процесс выдачи рекомендаций проходит в два шага где:

**1. Происходит обучение модели Faiss по IndexIVFFlat, где:**
* для тренировочной выборки выдается 10 ближайших векторов(для лучшего олучения)
* для валидационной выборки выдается 100 ближайших векторов(для бльшего шанса захвата эталонных векторов)

Создаются наборы данных из векоров train\valid & base, где позитивом отмечается эталонное совподение

**2. Обучается модель CatBoostClassifire для бинарной классификации.**
* Модель предсказывает вероятность позитивного совпадания ветора входа с вектором из базы товаров, после чего отбирается 5 самых вероятных совпадений для каждого индекса.



Эффективность модели рассчитывается по метрике Accuracy@5 -  показывает, как часто в списке из 5 лучших предлагаемых товаров содержится образец эталонного(отмеченного предложения) 

### Итоги проекта:

#### Общий результат

По результату обработки и построения эффективность работы двух моделей достигла точности в 59,85 %.

#### Эффективность модели faiss

* по результатам работы faiss, методом кластеризации, в 100 ближайших соседях для входящего id окажется 1 эталонно похожий продукт с вероятностью **~66%**

#### Эффективность модели CatBoostClassifire

* Модель CatBoost из 66% эталонных образцов в 100 предложенных векторах позволяет верно ранджировать 59.85% в верхнюю пятёрку, что позволяет вывести эффективность ранджирования моделью более - **90%**

### Варианты улучшения проекта:

Основываясь на точности выше, целевая задача данного проекта - максимизировать эффективность отбора ближайших векторов моделью faiss, что даст максимальный прирост к качеству итоговых предложений. На чём стоит сосредоточиться в дальнейшей работе с данными.

**Дальнейшее:**
1. Углубленная обработка данных под faiss: 
* Тестирование удаления столбцов признаков с большими отклонениями.
* Уменьшение размерности с помощью методики главных компонент(РСА)
* Совмещение Нормализации и Стандартизации, с использованием большего разнообразия доступных методик.
* В случаё получения непреодолимых пределов по faiss - тест иных моделей быстрых поисков соседей.

2. Для улучшения второй модели:
* Возможно использование более сильной(наполненной) тренировочной выборки, полученной полным перебором по faiss, без кластеризации.
* Усиленный поиск гиперпараметров.
* Тестирование отличных от CatBoostClassifier моделей, вроде LightGBM
